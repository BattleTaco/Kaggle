{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8c4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19026881",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = pd.read_csv('train.csv')\n",
    "TEST_DF = pd.read_csv('test.csv')\n",
    "STORES_DF = pd.read_csv('stores.csv')\n",
    "OIL_DF = pd.read_csv('oil.csv')\n",
    "HOLIDAYS_DF = pd.read_csv('holidays_events.csv')\n",
    "TRANSATIONS_DF = pd.read_csv('transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6593102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3000888, 6)\n",
      "\n",
      "Columns: ['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion']\n",
      "\n",
      "Missing values:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "id               int64\n",
      "date            object\n",
      "store_nbr        int64\n",
      "family          object\n",
      "sales          float64\n",
      "onpromotion      int64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "   id        date  store_nbr      family  sales  onpromotion\n",
      "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
      "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
      "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
      "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
      "4   4  2013-01-01          1       BOOKS    0.0            0\n",
      "\n",
      "Descriptive statistics:\n",
      "                 id     store_nbr         sales   onpromotion\n",
      "count  3.000888e+06  3.000888e+06  3.000888e+06  3.000888e+06\n",
      "mean   1.500444e+06  2.750000e+01  3.577757e+02  2.602770e+00\n",
      "std    8.662819e+05  1.558579e+01  1.101998e+03  1.221888e+01\n",
      "min    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00\n",
      "25%    7.502218e+05  1.400000e+01  0.000000e+00  0.000000e+00\n",
      "50%    1.500444e+06  2.750000e+01  1.100000e+01  0.000000e+00\n",
      "75%    2.250665e+06  4.100000e+01  1.958473e+02  0.000000e+00\n",
      "max    3.000887e+06  5.400000e+01  1.247170e+05  7.410000e+02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_info(df):\n",
    "    print(f\"Shape: {df.shape}\\n\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\\n\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\\n\")\n",
    "    print(f\"Data types:\\n{df.dtypes}\\n\")\n",
    "    print(f\"First 5 rows:\\n{df.head()}\\n\")\n",
    "    print(f\"Descriptive statistics:\\n{df.describe()}\\n\")\n",
    "    \n",
    "get_info(TRAIN_DF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbe8bc",
   "metadata": {},
   "source": [
    "For now, Lets start with a baseline without any additions as we know for sure that these other .csv files can drastically increase the score of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ad8492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['id', 'store_nbr', 'sales', 'onpromotion']\n",
      "Categorical columns: ['date', 'family']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_columns = TRAIN_DF.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_columns = TRAIN_DF.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns: {num_columns}\\n\"\n",
    "      f\"Categorical columns: {cat_columns}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d4bd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 3000888\n"
     ]
    }
   ],
   "source": [
    "def plot_numerical_distribution(df, columns):\n",
    "    for column in columns:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(df[column], kde=True)\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "        \n",
    "def plot_categorical_distribution(df, columns):\n",
    "    for column in columns:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.countplot(data=df, x=column)\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "        \n",
    "#plot_numerical_distribution(TRAIN_DF, num_columns)\n",
    "#plot_categorical_distribution(TRAIN_DF, cat_columns)\n",
    "print(f'Total Rows: {TRAIN_DF.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247a0bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA Count: id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'NA Count: {TRAIN_DF.isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36d4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TRAIN_DF.drop(columns=['id', 'date', 'sales'])\n",
    "y = TRAIN_DF['sales']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "num_columns_X = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_columns_X = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "numerical_pipeline = [\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # fills mising values with mean\n",
    "    ('scaler', StandardScaler()) # StandardScalar standardizes features\n",
    "]\n",
    "\n",
    "categorical_pipeline = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')), # fills missing values with most frequent value\n",
    "    ('onehot', OneHotEncoder(handle_unknown= 'ignore')) # OneHotEncoder converts categorical variables into dummy/indicator variables\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers= [\n",
    "        ('num', Pipeline(numerical_pipeline), num_columns_X),\n",
    "        ('cat', Pipeline(categorical_pipeline), cat_columns_X)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def train_baseline_model(X_train, y_train):\n",
    "    model = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            random_state=42,\n",
    "            tree_method = 'gpu_hist', # Use GPU for faster training\n",
    "            gpu_id = 0, # Specify GPU ID if multiple GPUs are available\n",
    "            n_jobs=-1 # Use all available CPU cores\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d10713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(TRAIN_DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5793971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/17 01:53:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/17 01:53:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "\n",
    "mlflow.set_experiment(\"store-sales-forecasting\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    baseline_model = train_baseline_model(X_train, y_train)\n",
    "    y_pred = baseline_model.predict(X_test)\n",
    "    \n",
    "    y_pred_clipped = np.maximum(y_pred, 0)\n",
    "    rmsle = root_mean_squared_log_error(y_test, y_pred_clipped)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_metric(\"rmsle\", rmsle)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.sklearn.log_model(baseline_model, \"baseline_tree_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6523af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 1.484578930356568\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSLE: {rmsle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0680c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kagenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
