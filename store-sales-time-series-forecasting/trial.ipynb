{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f01d0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2dd686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = pd.read_csv('train.csv')\n",
    "TEST_DF = pd.read_csv('test.csv')\n",
    "STORES_DF = pd.read_csv('stores.csv')\n",
    "OIL_DF = pd.read_csv('oil.csv')\n",
    "HOLIDAYS_DF = pd.read_csv('holidays_events.csv')\n",
    "TRANSATIONS_DF = pd.read_csv('transactions.csv')\n",
    "\n",
    "dataframes = [TRAIN_DF, TEST_DF, STORES_DF, OIL_DF, HOLIDAYS_DF, TRANSATIONS_DF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da14cf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames have null values: [np.False_, np.False_, np.False_, np.True_, np.False_, np.False_]\n",
      "\n",
      "DataFrame Shapes:\n",
      "(3000888, 6)\n",
      "(28512, 5)\n",
      "(54, 5)\n",
      "(1218, 2)\n",
      "(350, 6)\n",
      "(83488, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_info(df_list):\n",
    "    has_null = []\n",
    "    for df in df_list:\n",
    "        has_null.append(df.isnull().values.any())\n",
    "    print(\"DataFrames have null values:\", has_null)\n",
    "    print(\"\\nDataFrame Shapes:\")\n",
    "    for df in df_list:\n",
    "        print(df.shape)\n",
    "\n",
    "\n",
    "get_info(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c349826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Columns:\n",
      "['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion']\n",
      "['id', 'date', 'store_nbr', 'family', 'onpromotion']\n",
      "['store_nbr', 'city', 'state', 'type', 'cluster']\n",
      "['date', 'dcoilwtico']\n",
      "['date', 'type', 'locale', 'locale_name', 'description', 'transferred']\n",
      "['date', 'store_nbr', 'transactions']\n"
     ]
    }
   ],
   "source": [
    "def print_columns(df_list):\n",
    "    print(\"DataFrame Columns:\")\n",
    "    for df in df_list:\n",
    "        print(df.columns.tolist())\n",
    "    \n",
    "print_columns(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's not advisable to merge all dataframes at once without specifying keys.\n",
    "# You should merge them sequentially based on their relationships.\n",
    "\n",
    "# Merge strategy for TRAIN_DF:\n",
    "# 1. Merge STORES_DF on `store_nbr`.\n",
    "# 2. Merge OIL_DF on `date`.\n",
    "# 3. Merge HOLIDAYS_DF on `date`.\n",
    "# 4. Merge TRANSATIONS_DF on `date` and `store_nbr`.\n",
    "# The same logic applies to TEST_DF, except for TRANSATIONS_DF.\n",
    "\n",
    "# Let's make sure date columns are in datetime format\n",
    "TRAIN_DF['date'] = pd.to_datetime(TRAIN_DF['date'])\n",
    "OIL_DF['date'] = pd.to_datetime(OIL_DF['date'])\n",
    "HOLIDAYS_DF['date'] = pd.to_datetime(HOLIDAYS_DF['date'])\n",
    "TRANSATIONS_DF['date'] = pd.to_datetime(TRANSATIONS_DF['date'])\n",
    "\n",
    "# Start with the training data\n",
    "train_merged = TRAIN_DF.copy()\n",
    "\n",
    "# Merge with STORES_DF\n",
    "train_merged = pd.merge(train_merged, STORES_DF, on='store_nbr', how='left')\n",
    "print(f\"Shape after merging with STORES_DF: {train_merged.shape}\")\n",
    "\n",
    "# Merge with OIL_DF\n",
    "train_merged = pd.merge(train_merged, OIL_DF, on='date', how='left')\n",
    "print(f\"Shape after merging with OIL_DF: {train_merged.shape}\")\n",
    "\n",
    "# Merge with HOLIDAYS_DF\n",
    "# Note: This might create more rows if a date has multiple holidays.\n",
    "train_merged = pd.merge(train_merged, HOLIDAYS_DF, on='date', how='left')\n",
    "print(f\"Shape after merging with HOLIDAYS_DF: {train_merged.shape}\")\n",
    "\n",
    "# Merge with TRANSATIONS_DF\n",
    "train_merged = pd.merge(train_merged, TRANSATIONS_DF, on=['date', 'store_nbr'], how='left')\n",
    "print(f\"Shape after merging with TRANSATIONS_DF: {train_merged.shape}\")\n",
    "\n",
    "print(\"\\n--- Merged train data info ---\")\n",
    "train_merged.info()\n",
    "print(\"\\n--- Null values in merged train data ---\")\n",
    "print(train_merged.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kagenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
